{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca25dc7c",
   "metadata": {},
   "source": [
    "### Import libraries and set up connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24affe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import urllib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to MS SQL Server database\n",
    "load_dotenv()\n",
    "\n",
    "#get parameters from environmnet var\n",
    "pwd = os.getenv('mssql_pwd')\n",
    "uid = os.getenv('mssql_uid')\n",
    "#sql db details\n",
    "driver = os.getenv('mssql_driver')\n",
    "server = os.getenv('mssql_server')\n",
    "database = os.getenv(\"mssql_database\")\n",
    "\n",
    "params = urllib.parse.quote_plus(f\"DRIVER={driver};\"\n",
    "                            f\"SERVER={server};\"\n",
    "                            f\"DATABASE={database};\"\n",
    "                            \"Trusted_Connection=yes;\"\n",
    "                            \"TrustServerCertificate=yes\")\n",
    "\n",
    "mssql_engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing connection to postgres database\n",
    "pg_driver = os.getenv('postgre_driver') \n",
    "pg_database = os.getenv('postgre_database') \n",
    "pg_server = os.getenv('postgre_server') \n",
    "pg_port = os.getenv('postgre_port') \n",
    "pg_uid = os.getenv('postgre_uid') \n",
    "pg_pwd = os.getenv('postgre_pwd') \n",
    "\n",
    "pg_engine = create_engine(f'postgresql://{pg_uid}:{pg_pwd}@{pg_server}:{pg_port}/{pg_database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default date\n",
    "format_data = \"%d/%m/%Y %H:%M:%S.%f\"\n",
    "time_data = \"01/01/1900 00:00:0.000\"\n",
    "default_date = datetime.strptime(time_data, format_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa181c5",
   "metadata": {},
   "source": [
    "### Create a function to insert ETL Logs. To keep track of Last ETL Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertetllog(tblname, rowcount, status, error):\n",
    "    \"\"\" Function to insert data into the ETL log table in PostgreSQL. Captures the current run time and \n",
    "        end time of the ETL process and row_count along with any error messages.\n",
    "\n",
    "        tblName: Name of the table for which ETL process was run\n",
    "        rowcount: Number of rows inserted in the current process\n",
    "        status: Can be Y or N which denotes Success or Failure resepctively\n",
    "        error: Contains details of the error if any, for the current run  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # set record attributes\n",
    "        record = {\"tablename\":tblname,\"extractrowcount\": rowcount,\"starttime\":datetime.now(),\n",
    "                  \"endtime\":datetime.now(),\"lastextractdatetime\":datetime.now(),\"status\":status,\"errormessage\":error[0:490]}\n",
    "        #print(record)\n",
    "        #create df\n",
    "        inert_etl_log = pd.DataFrame(record, index=[0])\n",
    "        tbl_name = \"etlextractlog\"\n",
    "        inert_etl_log.to_sql(tbl_name, pg_engine, if_exists='append', index=False, schema=\"public\")\n",
    "    except Exception as e:\n",
    "        print(\"Unable to insert record into etl logs\" + print(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the log entry\n",
    "insertetllog(\"test\", 0, \"N\", \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastETLRunDate(tblName):\n",
    "    \"\"\" Function to return the timestamp of the last ETL process run date. If it doesn't exist\n",
    "        or the table has never been loaded before it will return a default date and enable \n",
    "        historical load of data.\n",
    "\n",
    "        tblName: Name of the table for which we want to check its last run date.  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        qry_logs = pd.read_sql_query(f\"\"\"Select max(lastextractdatetime) as lastETLRunDate\n",
    "        from public.etlextractlog where tablename = '{tblName}'\"\"\", pg_engine)\n",
    "        etlrundate = qry_logs['lastetlrundate'][0]\n",
    "        if not etlrundate:\n",
    "            etlrundate = default_date\n",
    "        return etlrundate\n",
    "    except Exception as e:\n",
    "        return default_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Last ETL run date\n",
    "stg_tbl = \"stg_customer\"\n",
    "lastrundate = getLastETLRunDate(stg_tbl)\n",
    "lastrundate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae342a0f",
   "metadata": {},
   "source": [
    "### Upsert Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770dac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_to_sql(df, table_name, primary_key):\n",
    "    \"\"\" This function creates a PostgreSQL Dynamic SQL statement to upsert records and executes it.\n",
    "        Creates a temp table to store the changed data temporarily and inserts into the main target table. \n",
    "\n",
    "        df: This is the data/changed_data from the source\n",
    "        tbl: This is the target table to where we want to load the data\n",
    "        key: primary key of the target table\n",
    "    \"\"\"\n",
    "    update = []\n",
    "    columns = []\n",
    "    temp_table = f\"{table_name}_temp\"\n",
    "    for col in df.columns:\n",
    "        columns.append(col)\n",
    "        if col == primary_key:\n",
    "            continue\n",
    "        update.append(f'\"{col}\"=EXCLUDED.\"{col}\"')\n",
    "    # Persist data to temp table\n",
    "    df.to_sql(temp_table, pg_engine, if_exists='replace', index=False, schema='public')\n",
    "    update_stmt_1 = \", \".join(f' \"{c}\" ' for c in columns )\n",
    "    insert_stmt_1 = f' INSERT INTO {table_name} ( {update_stmt_1} ) '\n",
    "    insert_stmt_2 = f' Select * from {temp_table} '\n",
    "    insert_stmt_3 = f' ON CONFLICT (\"{primary_key}\") '\n",
    "    insert_stmt_4 = f' DO UPDATE SET '\n",
    "    update_stmt_2 = \", \".join(update)\n",
    "\n",
    "    upsert_stmt = insert_stmt_1 + insert_stmt_2 + insert_stmt_3 + insert_stmt_4 + update_stmt_2 +  \";\"\n",
    "    print(upsert_stmt)\n",
    "    with pg_engine.begin() as cnx:\n",
    "        cnx.execute(upsert_stmt)\n",
    "    \n",
    "    #Drop the temporary table\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(bind=pg_engine)\n",
    "    table = metadata.tables[f\"{table_name}_temp\"]\n",
    "    metadata.drop_all(pg_engine, table, checkfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1203c",
   "metadata": {},
   "source": [
    "### Function to Insert and update records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert(df, tbl, key):\n",
    "    \"\"\" This function is used to detect if the load is historic or incremental based on last etl run date. \n",
    "        If incremental it makes use of the above upsert function update_to_sql() created to upsert the data\n",
    "        and insert details of the ETL in the ETL log table in PostgreSQL. \n",
    "\n",
    "        df: This is the data/changed_data from the source\n",
    "        tbl: This is the target table to where we want to load the data\n",
    "        key: primary key of the target table\n",
    "    \"\"\"\n",
    "    if(lastrundate == default_date):\n",
    "        try:\n",
    "            print('Historical Load')\n",
    "            df.to_sql(tbl, pg_engine, if_exists='replace', index=False, schema=\"public\")\n",
    "            insertetllog(tbl, len(df), \"Y\", \"NA\")\n",
    "        except Exception as e:  \n",
    "            insertetllog(tbl, len(df), \"N\", str(e))\n",
    "    else:\n",
    "        try:\n",
    "            print('Incremental Load')\n",
    "            update_to_sql(df, tbl, key)\n",
    "            insertetllog(tbl, len(df), \"Y\", \"NA\")\n",
    "        except Exception as e:  \n",
    "            insertetllog(tbl, len(df), \"N\", str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d27f64dd",
   "metadata": {},
   "source": [
    "### Source Change Detection Query. Only read new and modified records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e032110",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_sql_query(f\"\"\"  select *\n",
    "                            from [dbo].[customers]\n",
    "                            where  (Created_at   >= convert(datetime2,'{lastrundate}')\n",
    "                                or modified_at  >= convert(datetime2,'{lastrundate}')) \"\"\", mssql_engine)\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283520ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert(source, stg_tbl, \"customerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Target data into a dataframe\n",
    "logs = pd.read_sql('Select * from PUBLIC.\"etlextractlog\"', pg_engine)\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Target data \n",
    "target = pd.read_sql(f'Select * from public.\"{stg_tbl}\"', pg_engine)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e022f46",
   "metadata": {},
   "source": [
    "### Let's get the incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Last ETL run date\n",
    "stg_tbl = \"stg_customer\"\n",
    "lastrundate = getLastETLRunDate(stg_tbl)\n",
    "print(lastrundate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86214da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_sql_query(f\"\"\"  select *\n",
    "                            from [dbo].[customers]\n",
    "                            where  (Created_at   >= convert(datetime2,'{lastrundate}')\n",
    "                                or modified_at  >= convert(datetime2,'{lastrundate}')) \"\"\", mssql_engine)\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb611bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert(source, stg_tbl, \"customerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the target table if all updates and inserts are reflected\n",
    "target = pd.read_sql(f'Select * from public.\"{stg_tbl}\"', pg_engine)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61af71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ce3e963fa5f96800d47be60de4ee8482e7bfa5a09ff6a271e412b1263c00f3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
